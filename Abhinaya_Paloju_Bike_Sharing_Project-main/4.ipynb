{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c93cfe-87d5-4c22-8d99-9e0e001f30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "âœ… RandomForest results saved to results/tree_models_search.csv\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "âœ… GradientBoosting results saved to results/tree_models_search.csv\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "âœ… XGBoost results saved to results/tree_models_search.csv\n",
      "\n",
      "ðŸ“Š Final Results:\n",
      "              model       MAE      RMSE        R2  Adjusted_R2  \\\n",
      "0      RandomForest  2.659575  4.595428  0.999554     0.999552   \n",
      "1  GradientBoosting  0.299457  0.403226  0.999997     0.999997   \n",
      "2           XGBoost  0.054611  0.083225  1.000000     1.000000   \n",
      "\n",
      "                                         Best_Params  Train_Time  \n",
      "0  {'n_estimators': 100, 'max_features': 0.3, 'ma...   54.907524  \n",
      "1  {'subsample': 0.9, 'n_estimators': 500, 'max_d...  145.326069  \n",
      "2  {'subsample': 1.0, 'n_estimators': 500, 'max_d...   27.730578  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/hour.csv\", parse_dates=[\"dteday\"])\n",
    "X = df.drop(columns=[\"cnt\", \"dteday\"])\n",
    "y = df[\"cnt\"]\n",
    "\n",
    "# Time-aware cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Parameter grids\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [6, 10, None],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.3]\n",
    "}\n",
    "gb_param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"subsample\": [0.7, 0.9, 1.0]\n",
    "}\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.7, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Evaluation helper\n",
    "def evaluate_model(model_name, model, param_grid, X, y, tscv, results_path=\"results/tree_models_search.csv\"):\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=tscv,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    search.fit(X, y)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    # Use last validation split for evaluation\n",
    "    for train_idx, valid_idx in tscv.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    y_pred = best_model.predict(X_valid)\n",
    "\n",
    "    mae = mean_absolute_error(y_valid, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    n, p = len(y_valid), X_valid.shape[1]\n",
    "    adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "    result = pd.DataFrame([{\n",
    "        \"model\": model_name,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"Adjusted_R2\": adj_r2,\n",
    "        \"Best_Params\": search.best_params_,\n",
    "        \"Train_Time\": train_time\n",
    "    }])\n",
    "\n",
    "    # Save results\n",
    "    try:\n",
    "        old_results = pd.read_csv(results_path)\n",
    "        final_results = pd.concat([old_results, result], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        final_results = result\n",
    "\n",
    "    final_results.to_csv(results_path, index=False)\n",
    "    print(f\"\\nâœ… {model_name} results saved to {results_path}\")\n",
    "    return result\n",
    "\n",
    "# Run models\n",
    "rf_results = evaluate_model(\"RandomForest\", RandomForestRegressor(random_state=42), rf_param_grid, X, y, tscv)\n",
    "gb_results = evaluate_model(\"GradientBoosting\", GradientBoostingRegressor(random_state=42), gb_param_grid, X, y, tscv)\n",
    "xgb_results = evaluate_model(\"XGBoost\", XGBRegressor(objective=\"reg:squarederror\", random_state=42, n_jobs=-1), xgb_param_grid, X, y, tscv)\n",
    "\n",
    "# Final Results\n",
    "print(\"\\nðŸ“Š Final Results:\")\n",
    "print(pd.concat([rf_results, gb_results, xgb_results], ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870dadf-e198-426d-98cd-6d4bdce3413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
